{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "SJDFxu-NYRxr",
        "J29ln0WyrNWW",
        "7bOo4yD3nlJl",
        "xsEp1CmwnplD",
        "rPRH9Pq7rS4L",
        "ajsfZYjrusc9"
      ],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### README"
      ],
      "metadata": {
        "id": "Tl9B-AlFWuZi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## `Model.py`\n",
        "**What does the script do?**\n",
        "\n",
        "* **`build_rslds_model`** – create an input-driven rSLDS with configurable discrete states (`K`), latent dimension, stickiness (`kappa`), and AR emissions.  \n",
        "* **`fit_rslds_model`** – fit the model with variational inference; returns posterior means of latents/states and the ELBO curve.  \n",
        "* **`save_model_outputs`** – write all expected artifacts for downstream analysis:  \n",
        "  - `*model*.pkl` (fitted model)  \n",
        "  - `x_hat.npy` (latents)  \n",
        "  - `z_hat.npy` (discrete states)  \n",
        "  - `elbos.npy` (training curve)  \n",
        "  - `footshock.npy` (+ optional `speed.npy`, `pupil.npy`)  \n",
        "* **`load_model_outputs`** – reload artifacts in a consistent format for plotting/evaluation.  \n",
        "* Note: python 3.1 works the best with this model.\n",
        "\n",
        "---\n",
        "\n",
        "**Inputs**  \n",
        "\n",
        "* Wide-format CSV (time × neurons) and HDF5 with firing rates & footshock times.  \n",
        "* Configurable parameters: number of discrete states, latent dimension, learning settings.  \n",
        "\n",
        "---\n",
        "\n",
        "**Outputs (saved to run directory)**  \n",
        "\n",
        "* Latents (`x_hat.npy`), states (`z_hat.npy`), ELBO (`elbos.npy`), shock/speed/pupil vectors.  \n",
        "* Pickled model (`*model*.pkl`) for reproducibility and vector field plotting.  \n"
      ],
      "metadata": {
        "id": "SJDFxu-NYRxr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "1.   This notebook runs the different models for all rats and saves the outputs on drive.\n",
        "\n",
        "2.  This notebooks runs cross-validations for all rats and saves the outputs on drive.\n",
        "\n"
      ],
      "metadata": {
        "id": "TbYOlasZnWnq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mount Google Drive"
      ],
      "metadata": {
        "id": "J29ln0WyrNWW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xeltArJ7nTNq"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Clone SSM from git"
      ],
      "metadata": {
        "id": "7bOo4yD3nlJl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/lindermanlab/ssm.git\n",
        "!pip install git+https://github.com/lindermanlab/ssm.git --no-build-isolation"
      ],
      "metadata": {
        "id": "XyxyFq7snhsi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall -y numpy scipy numba scikit-learn pandas matplotlib seaborn autograd ssm\n",
        "!pip install \"numpy==1.26.4\" \"scipy==1.10.\" \"numba==0.58.\" \"scikit-learn==1.3.*\" \\\n",
        "            \"pandas==1.5.\" \"matplotlib==3.7.\" \"seaborn==0.12.*\""
      ],
      "metadata": {
        "id": "DelOkCJXuHyn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Clone rSLDS from git"
      ],
      "metadata": {
        "id": "xsEp1CmwnplD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/ElifAyten/rSLDS.git"
      ],
      "metadata": {
        "id": "e7LKy2LtnkfX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import the Libraries"
      ],
      "metadata": {
        "id": "rPRH9Pq7rS4L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "import traceback\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "DRIVE = Path(\"/content/drive/My Drive/rSLDS\")\n",
        "from rSLDS.cross_validation import crossval_rslds\n",
        "from rSLDS.modelling import fit_single_rslds"
      ],
      "metadata": {
        "id": "AQZ3qK6NskTg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Runs"
      ],
      "metadata": {
        "id": "ajsfZYjrusc9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# model runner for all rats\n",
        "\n",
        "RAT_IDS = [3, 4, 8, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21]\n",
        "\n",
        "# Which areas to run the model with\n",
        "\n",
        "# subsets (can be discarded)\n",
        "AREA_SUBSETS = [\n",
        "    (\"ventral\",  \"allActive\"),\n",
        "    (\"ventral\",  \"responsive\"),\n",
        "    (\"dorsal\",   \"allActive\"),\n",
        "    (\"dorsal\",   \"responsive\"),\n",
        "    (\"thalamus\", \"allActive\"),\n",
        "    (\"thalamus\", \"responsive\"),\n",
        "]\n",
        "\n",
        "# only responsive for all areas combined\n",
        "RUN_RESPONSIVE_ALL = True\n",
        "\n",
        "# hyperparameter grid\n",
        "K_GRID        = [4]          # number of discrete states to try (can change)\n",
        "SEEDS         = [0, 1]          # repeat runs with different random seeds\n",
        "KAPPA_GRID    = [0.0]           # stickiness values to try\n",
        "\"\"\" f κ = 0 → the model might switch states too rapidly, even within 1–2 time bins, just to explain small fluctuations in the firing rates.\n",
        "If κ is larger → the model assumes states are more stable in time (like “once you’re in a shock-response state, you’ll stay there for a while”).\"\"\"\n",
        "NUM_ITERS     = 300\n",
        "OVERWRITE     = True            # if False, existing run folders will be skipped\n",
        "VERBOSE       = True\n",
        "\n",
        "# latent dimensionality: None -> auto using variance_goal\n",
        "LATENT_DIM      = None\n",
        "VARIANCE_GOAL   = 0.90 # we choose 90 % variance but can also be 95 %\n",
        "\n",
        "# helper for the paths\n",
        "def h5_path_for_rat(rid: int) -> Path:\n",
        "    return (\n",
        "        DRIVE / \"Rat-Data-hdf5\" / f\"Rat{rid}\" /\n",
        "        \"NpxFiringRate_Behavior_SBL_10msBINS_0smoothing.hdf5\"\n",
        "    )\n",
        "\n",
        "def csv_path_area(rid: int, area: str, subset: str) -> Path:\n",
        "    return (\n",
        "        DRIVE / \"Sub-Data\" / \"Seperate-by-Area\" / f\"Rat{rid}\" /\n",
        "        f\"area_splits_rat{rid}_{subset}\" / f\"{area}_wide.csv\"\n",
        "    )\n",
        "\n",
        "def csv_path_responsive_all(rid: int) -> Path:\n",
        "    return (\n",
        "        DRIVE / \"Sub-Data\" / \"Only-Responsive\" / f\"Rat{rid}\" /\n",
        "        f\"area_splits_rat{rid}_responsive\" / \"responsive_rates_raw.csv\"\n",
        "    )\n",
        "\n",
        "def base_model_dir(rid: int) -> Path:\n",
        "    return DRIVE / \"rSLDS-Model-Outputs\" / f\"Rat{rid}-Model-Outputs\"\n",
        "\n",
        "def run_dir(rid: int, suffix: str, K: int, seed: int, kappa: float) -> Path:\n",
        "    \"\"\"\n",
        "    Make a unique folder per configuration:\n",
        "    models_Rat{rid}_{suffix}_K{K}_seed{seed}_kappa{kappa}\n",
        "    Example: models_Rat15_dorsal_responsive_K2_seed0_kappa0.0\n",
        "    \"\"\"\n",
        "    name = f\"models_Rat{rid}_{suffix}_K{K}_seed{seed}_kappa{kappa:g}\"\n",
        "    return base_model_dir(rid) / name\n",
        "\n",
        "def suffix_from(area: str | None, subset: str | None) -> str:\n",
        "    if area is None and subset == \"responsive\":\n",
        "        return \"responsive_all\"\n",
        "    if subset == \"responsive\":\n",
        "        return f\"{area}_responsive\"\n",
        "    elif subset == \"allActive\":\n",
        "        return f\"{area}\"\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown (area={area}, subset={subset})\")\n",
        "\n",
        "# running\n",
        "def run_fit(h5_path: Path, csv_path: Path, save_dir: Path,\n",
        "            K_states: int, seed: int, kappa: float):\n",
        "    \"\"\"\n",
        "    Wraps fit_single_rslds with standard args; returns a dict summary.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        save_dir.parent.mkdir(parents=True, exist_ok=True)\n",
        "        if not h5_path.exists():\n",
        "            return dict(status=\"skip_h5_missing\", path=str(save_dir), msg=str(h5_path))\n",
        "        if not csv_path.exists():\n",
        "            return dict(status=\"skip_csv_missing\", path=str(save_dir), msg=str(csv_path))\n",
        "\n",
        "        print(f\"→ fit: K={K_states}, seed={seed}, kappa={kappa:g}\")\n",
        "        res = fit_single_rslds(\n",
        "            h5_path     = h5_path,\n",
        "            csv_path    = csv_path,\n",
        "            save_dir    = save_dir,\n",
        "            K_states    = K_states,\n",
        "            num_iters   = NUM_ITERS,\n",
        "            kappa       = kappa,\n",
        "            overwrite   = OVERWRITE,\n",
        "            verbose     = VERBOSE,\n",
        "            latent_dim  = LATENT_DIM,\n",
        "            variance_goal = VARIANCE_GOAL,\n",
        "        )\n",
        "        return dict(status=\"ok\", path=str(save_dir), msg=\"trained\")\n",
        "    except FileExistsError as e:\n",
        "        return dict(status=\"skip_exists\", path=str(save_dir), msg=str(e))\n",
        "    except Exception as e:\n",
        "        traceback.print_exc(limit=1)\n",
        "        return dict(status=\"error\", path=str(save_dir), msg=f\"{type(e).__name__}: {e}\")\n",
        "\n",
        "# loop it\n",
        "summ_rows = []\n",
        "\n",
        "for rid in RAT_IDS:\n",
        "    h5p = h5_path_for_rat(rid)\n",
        "\n",
        "    # per-area/subset grid\n",
        "    for area, subset in AREA_SUBSETS:\n",
        "        csvp   = csv_path_area(rid, area, subset)\n",
        "        suffix = suffix_from(area, subset)\n",
        "\n",
        "        for K in K_GRID:\n",
        "            for seed in SEEDS:\n",
        "                for kappa in KAPPA_GRID:\n",
        "                    savedir = run_dir(rid, suffix, K, seed, kappa)\n",
        "                    base_model_dir(rid).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "                    print(f\"[Rat {rid:2d}] {suffix:20s}  K={K} seed={seed} kappa={kappa:g}\")\n",
        "                    info = run_fit(h5p, csvp, savedir, K, seed, kappa)\n",
        "                    summ_rows.append({\n",
        "                        \"rat\": rid, \"suffix\": suffix,\n",
        "                        \"K\": K, \"seed\": seed, \"kappa\": kappa,\n",
        "                        \"status\": info[\"status\"], \"path\": info[\"path\"], \"msg\": info[\"msg\"]\n",
        "                    })\n",
        "\n",
        "    # combined responsive_all\n",
        "    if RUN_RESPONSIVE_ALL:\n",
        "        area, subset = None, \"responsive\"\n",
        "        csvp   = csv_path_responsive_all(rid)\n",
        "        suffix = suffix_from(area, subset)\n",
        "\n",
        "        for K in K_GRID:\n",
        "            for seed in SEEDS:\n",
        "                for kappa in KAPPA_GRID:\n",
        "                    savedir = run_dir(rid, suffix, K, seed, kappa)\n",
        "                    base_model_dir(rid).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "                    print(f\"[Rat {rid:2d}] {suffix:20s}  K={K} seed={seed} kappa={kappa:g}\")\n",
        "                    info = run_fit(h5p, csvp, savedir, K, seed, kappa)\n",
        "                    summ_rows.append({\n",
        "                        \"rat\": rid, \"suffix\": suffix,\n",
        "                        \"K\": K, \"seed\": seed, \"kappa\": kappa,\n",
        "                        \"status\": info[\"status\"], \"path\": info[\"path\"], \"msg\": info[\"msg\"]\n",
        "                    })\n",
        "\n",
        "# summary csv\n",
        "summary_dir = DRIVE / \"rSLDS-Model-Outputs\" / \"_run_summaries\"\n",
        "summary_dir.mkdir(parents=True, exist_ok=True)\n",
        "summary_csv = summary_dir / \"rslds_fits_summary.csv\"\n",
        "pd.DataFrame(summ_rows).to_csv(summary_csv, index=False)"
      ],
      "metadata": {
        "id": "fwPva928pHwG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cross Validation"
      ],
      "metadata": {
        "id": "WF7KzfbgumrA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DRIVE = Path(\"/content/drive/My Drive/rSLDS\")\n",
        "\n",
        "RAT_IDS = [3, 4, 8, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21]\n",
        "\n",
        "AREA_SUBSETS = [\n",
        "    (\"ventral\",  \"allActive\"),\n",
        "    (\"ventral\",  \"responsive\"),\n",
        "    (\"dorsal\",   \"allActive\"),\n",
        "    (\"dorsal\",   \"responsive\"),\n",
        "    (\"thalamus\", \"allActive\"),\n",
        "    (\"thalamus\", \"responsive\"),\n",
        "]\n",
        "\n",
        "RUN_RESPONSIVE_ALL = True\n",
        "\n",
        "K_GRID       = [4]     # use 4-state models (change if needed)\n",
        "N_FOLDS      = 5\n",
        "SEEDS        = [0, 1]  # optional repeats with different seeds\n",
        "NUM_ITERS    = 300\n",
        "VERBOSE      = True\n",
        "\n",
        "\n",
        "# helper for path\n",
        "def h5_path_for_rat(rid: int) -> Path:\n",
        "    return DRIVE / \"Rat-Data-hdf5\" / f\"Rat{rid}\" / \"NpxFiringRate_Behavior_SBL_10msBINS_0smoothing.hdf5\"\n",
        "\n",
        "def csv_path_area(rid: int, area: str, subset: str) -> Path:\n",
        "    return DRIVE / \"Sub-Data\" / \"Seperate-by-Area\" / f\"Rat{rid}\" / f\"area_splits_rat{rid}_{subset}\" / f\"{area}_wide.csv\"\n",
        "\n",
        "def csv_path_responsive_all(rid: int) -> Path:\n",
        "    return DRIVE / \"Sub-Data\" / \"Only-Responsive\" / f\"Rat{rid}\" / f\"area_splits_rat{rid}_responsive\" / \"responsive_rates_raw.csv\"\n",
        "\n",
        "def suffix_from(area: str | None, subset: str | None) -> str:\n",
        "    if area is None and subset == \"responsive\":\n",
        "        return \"responsive_all\"\n",
        "    if subset == \"responsive\":\n",
        "        return f\"{area}_responsive\"\n",
        "    elif subset == \"allActive\":\n",
        "        return f\"{area}\"\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown (area={area}, subset={subset})\")\n",
        "\n",
        "def cv_save_dir(rid: int, suffix: str, K: int, seed: int) -> Path:\n",
        "    base = DRIVE / \"rSLDS-Model-Outputs\" / f\"Rat{rid}-Model-Outputs\" / \"cross_validation\"\n",
        "    return base / f\"models_Rat{rid}_{suffix}_K{K}_seed{seed}\"\n",
        "\n",
        "# run\n",
        "def run_cv(h5_path: Path, csv_path: Path, save_dir: Path, K_states: int, seed: int):\n",
        "    try:\n",
        "        save_dir.mkdir(parents=True, exist_ok=True)\n",
        "        if not h5_path.exists():\n",
        "            return dict(status=\"skip_h5_missing\", path=str(save_dir), msg=str(h5_path))\n",
        "        if not csv_path.exists():\n",
        "            return dict(status=\"skip_csv_missing\", path=str(save_dir), msg=str(csv_path))\n",
        "\n",
        "        print(f\"→ CV: K={K_states}, seed={seed}, folds={N_FOLDS}\")\n",
        "        res = crossval_rslds(\n",
        "            h5_path   = h5_path,\n",
        "            csv_path  = csv_path,\n",
        "            save_dir  = save_dir,\n",
        "            K_states  = K_states,\n",
        "            num_iters = NUM_ITERS,\n",
        "            n_folds   = N_FOLDS,\n",
        "            verbose   = VERBOSE,\n",
        "        )\n",
        "        try:\n",
        "            if isinstance(res, pd.DataFrame):\n",
        "                res.to_csv(save_dir / \"cv_results.csv\", index=False)\n",
        "            elif isinstance(res, dict):\n",
        "                pd.DataFrame([res]).to_csv(save_dir / \"cv_results.csv\", index=False)\n",
        "        except Exception as _:\n",
        "            pass\n",
        "\n",
        "        return dict(status=\"ok\", path=str(save_dir), msg=\"cv_done\")\n",
        "    except Exception as e:\n",
        "        traceback.print_exc(limit=1)\n",
        "        return dict(status=\"error\", path=str(save_dir), msg=f\"{type(e).__name__}: {e}\")\n",
        "\n",
        "# loop it\n",
        "summ_rows = []\n",
        "\n",
        "for rid in RAT_IDS:\n",
        "    h5p = h5_path_for_rat(rid)\n",
        "    # per-area/subset grid\n",
        "    for area, subset in AREA_SUBSETS:\n",
        "        csvp   = csv_path_area(rid, area, subset)\n",
        "        suffix = suffix_from(area, subset)\n",
        "\n",
        "        for K in K_GRID:\n",
        "            for seed in SEEDS:\n",
        "                out = cv_save_dir(rid, suffix, K, seed)\n",
        "                print(f\"[Rat {rid:2d}] {suffix:20s}  K={K} seed={seed}\")\n",
        "                info = run_cv(h5p, csvp, out, K, seed)\n",
        "                summ_rows.append({\n",
        "                    \"rat\": rid, \"suffix\": suffix, \"K\": K, \"seed\": seed,\n",
        "                    \"status\": info[\"status\"], \"path\": info[\"path\"], \"msg\": info[\"msg\"]\n",
        "                })\n",
        "    # combined responsive_all\n",
        "    if RUN_RESPONSIVE_ALL:\n",
        "        area, subset = None, \"responsive\"\n",
        "        csvp   = csv_path_responsive_all(rid)\n",
        "        suffix = suffix_from(area, subset)\n",
        "\n",
        "        for K in K_GRID:\n",
        "            for seed in SEEDS:\n",
        "                out = cv_save_dir(rid, suffix, K, seed)\n",
        "                print(f\"[Rat {rid:2d}] {suffix:20s}  K={K} seed={seed}\")\n",
        "                info = run_cv(h5p, csvp, out, K, seed)\n",
        "                summ_rows.append({\n",
        "                    \"rat\": rid, \"suffix\": suffix, \"K\": K, \"seed\": seed,\n",
        "                    \"status\": info[\"status\"], \"path\": info[\"path\"], \"msg\": info[\"msg\"]\n",
        "                })\n",
        "\n",
        "# summary csv\n",
        "summary_dir = DRIVE / \"rSLDS-Model-Outputs\" / \"_run_summaries\"\n",
        "summary_dir.mkdir(parents=True, exist_ok=True)\n",
        "summary_csv = summary_dir / \"rslds_crossval_summary.csv\"\n",
        "pd.DataFrame(summ_rows).to_csv(summary_csv, index=False)\n"
      ],
      "metadata": {
        "id": "chmB9RsXsdrd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
