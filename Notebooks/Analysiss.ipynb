{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "TQA6jbQIU930",
        "PZyUhFm_WpaD",
        "3PLyRbzE4Mwa",
        "rDgpop-249Vy",
        "X5kGiBeZ5mcN",
        "OG0PWlNqUJYQ",
        "VY5g-PVhUvrC"
      ],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### README"
      ],
      "metadata": {
        "id": "D0xyQBDxWdON"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## `Analysis.py`\n",
        "\n",
        "**What does the script do?**\n",
        "\n",
        "* **Latents vs. footshock** – saves per-latent plots (`latentXX.png`/`.pdf`).  \n",
        "* **Latents vs. speed** – overlays speed trace with latent states and keeps the footshocks.  \n",
        "* **Latents vs. pupil** – aligns/cleans pupil, overlays per latent, pupil axis ≥ 0.  \n",
        "* **Discrete states (two styles)** – exports `states_style1.png` and `states_style2.png` the two styles are only different in how they look if there are too litle state changes we make the changes more visible.  \n",
        "* **Switch statistics** – computes count, rate (/min), occupancy; saves PNGs + CSV of stats.  \n",
        "* **Mutual information (MI)** – per latent vs. speed/pupil; saves detailed CSVs and bar plots.  \n",
        "* **MI pre/post shock** – bar chart + CSV with FDR/perm statistics.  \n",
        "* **Vector fields** – plots rSLDS state-wise latent flow in PCA (2 ) plane.  \n",
        "* **Forward Simulation Error (FSE)** – plots MSE vs. horizon curve + saves `FSE.npy`.  \n",
        "\n",
        "---\n",
        "\n",
        "**Inputs (expected on Drive)**  \n",
        "\n",
        "* Model outputs per rat/variant: `x_hat.npy`, `z_hat.npy`, `footshock.npy`, optionally `speed.npy`, `pupil.npy`, and model pickle (`*model*.pkl`).  \n",
        "* Area/Responsive CSVs (wide format, must include `time_s`).  \n",
        "* HDF5 per rat for signals when not available in CSV (e.g., `NpxFiringRate_Behavior_SBL_10msBINS_0smoothing.hdf5`).  \n",
        "\n",
        "---\n",
        "\n",
        "**Where it writes**  \n",
        "\n",
        "* `/content/drive/My Drive/rSLDS/All-Plots/latents_footshock/…`  \n",
        "* `/latents_speed/…`, `/latents_pupil/…`, `/discrete_states_both/…`  \n",
        "* `/switch_summary/…`, `/mi_speed/…`, `/mi_pupil/…`, `/mi_prepost/…`  \n",
        "* `/vector_fields/…`, `/fse/…`  \n",
        "\n",
        "---\n",
        "\n",
        "**How to run (in Colab)**  \n",
        "\n",
        "* Open the notebook or run the exported `analysis.py` in Colab.  \n",
        "* Set lists: `RAT_IDS`, `MODEL_SUFFIXES`.  \n",
        "* Check Drive paths at the top of each section.  \n",
        "* Run only the cells/sections you need.  \n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "TQA6jbQIU930"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This notebook analsis the results of the rSLDS model and saves the outputs on drive."
      ],
      "metadata": {
        "id": "6zxH7vpqtp-R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Installations and Imports"
      ],
      "metadata": {
        "id": "PZyUhFm_WpaD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sp3PaQTa5uUV"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall -y numpy scipy numba scikit-learn pandas matplotlib seaborn autograd ssm\n",
        "!pip install \"numpy==1.26.4\" \"scipy==1.10.\" \"numba==0.58.\" \"scikit-learn==1.3.*\" \\\n",
        "            \"pandas==1.5.\" \"matplotlib==3.7.\" \"seaborn==0.12.*\""
      ],
      "metadata": {
        "id": "E873HT1atSW1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/lindermanlab/ssm.git\n",
        "!pip install git+https://github.com/lindermanlab/ssm.git --no-build-isolation"
      ],
      "metadata": {
        "id": "TQYVZndT8aTA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/ElifAyten/rSLDS.git"
      ],
      "metadata": {
        "id": "-J2ajIZh8vWp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# Standard library\n",
        "# =========================\n",
        "import os\n",
        "import sys\n",
        "import glob\n",
        "import pickle\n",
        "import traceback\n",
        "from pathlib import Path\n",
        "\n",
        "import h5py\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy import stats\n",
        "from scipy.ndimage import gaussian_filter1d\n",
        "from scipy.interpolate import interp1d\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "import ssm  # recurrent SLDS package\n",
        "\n",
        "repo_root = Path(\"/content/rSLDS\")\n",
        "if str(repo_root) not in sys.path:\n",
        "    sys.path.insert(0, str(repo_root))\n",
        "\n",
        "from rSLDS.load_dataset import load_rat_data\n",
        "from rSLDS.pca import pca_summary, plot_pca_cumsum\n",
        "from rSLDS.normalize_firing_rates import normalize_firing_rates\n",
        "from rSLDS.match_data_with_metadata import match_units_to_hdf5\n",
        "from rSLDS.population_acitivity_region import population_activity_by_region\n",
        "from rSLDS.create_sub_data import export_area_splits\n",
        "from rSLDS.create_sub_data_2 import export_responsive_tables\n",
        "from rSLDS.modelling import fit_single_rslds\n",
        "\n",
        "from rSLDS.plot_latents_footshock import load_and_plot_latents\n",
        "from rSLDS.plot_latents_speed import plot_latents_speed_shocks\n",
        "from rSLDS.plot_latents_pupil import plot_latents_pupil_shocks\n",
        "\n",
        "from rSLDS.plot_discrete_states import plot_discrete_states          # style 1\n",
        "from rSLDS.plot_discrete_states2 import plot_discrete_states2        # style 2\n",
        "\n",
        "from rSLDS.mutual_information import latent_signal_mi, compare_mi_pre_post\n",
        "from rSLDS.mi_pre_post import mi_pre_post_plot\n",
        "\n",
        "from rSLDS.second_dimensionality_reduction import plot_rslds_vector_field\n",
        "from rSLDS.forward_simulation_error import compute_and_plot_fse\n",
        "from rSLDS.forward_simulation_error_observed import compute_and_plot_fse_observed_AR\n",
        "\n",
        "from rSLDS.switch_statistics import switch_statistics, plot_switch_summary\n",
        "\n"
      ],
      "metadata": {
        "id": "o2pIU-i28gZJ"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plot Footshock With Latents"
      ],
      "metadata": {
        "id": "AUeatI18AKxY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plots latent dimensions with footshocks"
      ],
      "metadata": {
        "id": "OgEOsofeTPTI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Compatible with the old model runs and the old data on drive"
      ],
      "metadata": {
        "id": "3PLyRbzE4Mwa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "RAT_IDS = [3, 4, 8, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21]\n",
        "MODEL_SUFFIXES = [\n",
        "    \"ventral_responsive\", \"ventral\",\n",
        "    \"dorsal_responsive\", \"dorsal\",\n",
        "    \"responsive_all\",\n",
        "    \"thalamus_responsive\", \"thalamus\",\n",
        "]\n",
        "\n",
        "DEST_ROOT = Path(\"/content/drive/My Drive/rSLDS/All-Plots/latents_footshock\")\n",
        "\n",
        "for rid in RAT_IDS:\n",
        "    rat_root = Path(f\"/content/drive/My Drive/rSLDS/rSLDS-Model-Outputs/Rat{rid}-Model-Outputs\")\n",
        "    if not rat_root.exists():\n",
        "        print(f\"[Rat {rid}]missing folder.\")\n",
        "        continue\n",
        "    for suffix in MODEL_SUFFIXES:\n",
        "        model_sub = f\"models_Rat{rid}_{suffix}\"\n",
        "        model_dir = rat_root / model_sub\n",
        "        x_file = model_dir / \"x_hat.npy\"\n",
        "        shock_file = model_dir / \"footshock.npy\"\n",
        "\n",
        "        if not (x_file.exists() and shock_file.exists()):\n",
        "            print(f\"[Rat {rid}]  {suffix:20s} skipp.\")\n",
        "            continue\n",
        "\n",
        "        print(f\"[Rat {rid}]  {suffix:20s} → plotting…\")\n",
        "\n",
        "        try:\n",
        "            fig_list = load_and_plot_latents(\n",
        "                base_dir=str(rat_root),\n",
        "                rat_tag=\"\",\n",
        "                model_sub=model_sub,\n",
        "                integrate=True,\n",
        "                smooth_sigma=3.0,\n",
        "                colors=(\"k\",),\n",
        "                figsize=(10, 4),\n",
        "                return_fig=True,\n",
        "            )\n",
        "        except Exception as e:\n",
        "            print(f\"no plotting  ({type(e).__name__}: {e})\")\n",
        "            traceback.print_exc(limit=1)\n",
        "            continue\n",
        "\n",
        "        out_dir = DEST_ROOT / f\"Rat{rid}\" / model_sub\n",
        "        out_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "        for k, fig in enumerate(fig_list, start=1):\n",
        "            for ext in (\"png\", \"pdf\"):  # save both formats\n",
        "                fout = out_dir / f\"latent{k:02d}.{ext}\"\n",
        "                fig.savefig(fout, dpi=300, bbox_inches=\"tight\")\n",
        "            plt.close(fig)\n",
        "        print(f\"saved {len(fig_list)}→ {out_dir}\")"
      ],
      "metadata": {
        "id": "aTaLNfyT_ERQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plot Latents With Speed"
      ],
      "metadata": {
        "id": "Efe4shNnGL4H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plots latent dimensions with speed"
      ],
      "metadata": {
        "id": "eZz_St2WTMVO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Compatible with the old model runs and the old data on drive"
      ],
      "metadata": {
        "id": "rDgpop-249Vy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "RAT_IDS        = [3, 4, 8,10,11,13,14,15,16,17,18,19,20,21]\n",
        "MODEL_SUFFIXES = [\n",
        "    \"ventral_responsive\",\"ventral\",\n",
        "    \"dorsal_responsive\",\"dorsal\",\n",
        "    \"responsive_all\",\n",
        "    \"thalamus_responsive\",\"thalamus\",\n",
        "]\n",
        "\n",
        "DEST_ROOT = Path(\"/content/drive/My Drive/rSLDS/All-Plots/latents_speed\")\n",
        "\n",
        "for rid in RAT_IDS:\n",
        "    rat_root = Path(f\"/content/drive/My Drive/rSLDS/rSLDS-Model-Outputs/Rat{rid}-Model-Outputs\")\n",
        "    if not rat_root.exists():\n",
        "        print(f\"[Rat {rid}] missing folder.\")\n",
        "        continue\n",
        "\n",
        "    for suffix in MODEL_SUFFIXES:\n",
        "        model_sub  = f\"models_Rat{rid}_{suffix}\"\n",
        "        model_dir  = rat_root / model_sub\n",
        "        x_file     = model_dir / \"x_hat.npy\"\n",
        "        shock_file = model_dir / \"footshock.npy\"\n",
        "        speed_file = model_dir / \"speed.npy\"\n",
        "\n",
        "        if not (x_file.exists() and shock_file.exists() and speed_file.exists()):\n",
        "            continue\n",
        "\n",
        "        print(f\"[Rat {rid}]  {suffix:20s}plotting.\")\n",
        "\n",
        "        try:\n",
        "            x_latents = np.load(x_file)\n",
        "            footshock = np.load(shock_file)\n",
        "            speed     = np.load(speed_file)\n",
        "\n",
        "            # 10 ms bins\n",
        "            duration  = len(speed) * 0.01\n",
        "            figs = plot_latents_speed_shocks(\n",
        "                x_latents               = x_latents,\n",
        "                speed                   = speed,\n",
        "                footshock_input         = footshock,\n",
        "                duration                = duration,\n",
        "                smooth_sigma_lat_s      = 0.10,   # 100 ms latent smoothing\n",
        "                speed_smooth_sigma_s    = 0.20,   # 200 ms speed smoothing\n",
        "                integrate_latent        = True,\n",
        "                latent_color            = \"black\",\n",
        "                speed_color             = \"tab:blue\",\n",
        "                figsize                 = (10, 4),\n",
        "                return_figs             = True,\n",
        "            )\n",
        "        except Exception as e:\n",
        "            print(f\" failed to save({type(e).__name__}: {e})\")\n",
        "            traceback.print_exc(limit=1)\n",
        "            continue\n",
        "        out_dir = DEST_ROOT / f\"Rat{rid}\" / model_sub\n",
        "        out_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "        for k, fig in enumerate(figs, start=1):\n",
        "            for ext in (\"png\", \"pdf\"):  # save both formats\n",
        "                fout = out_dir / f\"latent{k:02d}.{ext}\"\n",
        "                fig.savefig(fout, dpi=300, bbox_inches=\"tight\")\n",
        "            plt.close(fig)\n",
        "        print(f\"saved {len(figs)} figures in PNG and PDF {out_dir}\")"
      ],
      "metadata": {
        "id": "rAuUjl0BB-B0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plot Latents With Pupil"
      ],
      "metadata": {
        "id": "4yzN9kMxWUWO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Compatible with the old model runs and the old data on drive"
      ],
      "metadata": {
        "id": "X5kGiBeZ5mcN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DRIVE = Path(\"/content/drive/My Drive\")\n",
        "\n",
        "MODEL_ROOT = DRIVE / \"rSLDS/rSLDS-Model-Outputs\"\n",
        "HDF5_ROOT  = DRIVE / \"rSLDS/Rat-Data-hdf5\"\n",
        "DEST_ROOT  = DRIVE / \"rSLDS/All-Plots/latents_pupil\"\n",
        "\n",
        "H5_NAME = \"NpxFiringRate_Behavior_SBL_10msBINS_0smoothing.hdf5\"\n",
        "\n",
        "RAT_IDS = [3,4,8,10,11,13,14,15,16,17,18,19,20,21]\n",
        "MODEL_SUFFIXES = [\n",
        "    \"ventral_responsive\",\"ventral\",\n",
        "    \"dorsal_responsive\",\"dorsal\",\n",
        "    \"responsive_all\",\n",
        "    \"thalamus_responsive\",\"thalamus\",\n",
        "]\n",
        "\n",
        "SMOOTH_SIGMA_S = 0.20    # seconds of smoothing for pupil\n",
        "PCLIP = (1, 99)          # robust clip percentiles\n",
        "FIGSIZE = (12, 4)\n",
        "\n",
        "#helpers\n",
        "\n",
        "def load_pupil_from_h5(h5):\n",
        "    \"\"\"\n",
        "    Try several common keys (flat and nested) for the pupil signal.\n",
        "    Returns (pupil_array, used_key or None).\n",
        "    \"\"\"\n",
        "    candidates = [\n",
        "        \"pupil_diameter\", \"pupil\", \"pupil_size\",\n",
        "        \"behavior/pupil_diameter\", \"behavior/pupil\", \"behavior/pupil_size\"\n",
        "    ]\n",
        "    for key in candidates:\n",
        "        if key in h5:\n",
        "            return h5[key][...], key\n",
        "    found = []\n",
        "    def _visit(name, obj):\n",
        "        if isinstance(obj, h5py.Dataset) and \"pupil\" in name.lower():\n",
        "            found.append(name)\n",
        "    h5.visititems(_visit)\n",
        "    if found:\n",
        "        return h5[found[0]][...], found[0]\n",
        "    return None, None\n",
        "\n",
        "\n",
        "def preprocess_pupil_raw(time_vec, pupil_vec, *, smooth_sigma_s=SMOOTH_SIGMA_S, pclip=PCLIP):\n",
        "    \"\"\"\n",
        "    Smooth (optional) + robust clip to kill spikes, but **keep raw units**.\n",
        "    No z-scoring, no normalization.\n",
        "    \"\"\"\n",
        "    t = np.asarray(time_vec, float).ravel()\n",
        "    p = np.asarray(pupil_vec, float).ravel()\n",
        "\n",
        "    if smooth_sigma_s and smooth_sigma_s > 0:\n",
        "        dt = float(t[1] - t[0]) if t.size > 1 else 1.0\n",
        "        sigma = max(smooth_sigma_s / dt, 1e-9)\n",
        "        p = gaussian_filter1d(p, sigma=sigma, mode=\"reflect\")\n",
        "\n",
        "    if pclip is not None:\n",
        "        lo, hi = np.nanpercentile(p, pclip)\n",
        "        if np.isfinite(lo) and np.isfinite(hi) and hi > lo:\n",
        "            p = np.clip(p, lo, hi)\n",
        "\n",
        "    return p\n",
        "\n",
        "\n",
        "def build_footshock_mask(time_vec, shock_times):\n",
        "    \"\"\"\n",
        "    Map shock timestamps onto the time grid using nearest-sample within ±½ dt.\n",
        "    Robust against float mismatches (avoids np.isin on floats).\n",
        "    \"\"\"\n",
        "    t = np.asarray(time_vec, float).ravel()\n",
        "    st = np.asarray(shock_times, float).ravel()\n",
        "    mask = np.zeros_like(t, dtype=bool)\n",
        "    if t.size < 2 or st.size == 0:\n",
        "        return mask\n",
        "    idx = np.searchsorted(t, st, side=\"left\")\n",
        "    idx = np.clip(idx, 0, len(t)-1)\n",
        "    dt = float(np.median(np.diff(t)))\n",
        "    close = np.abs(t[idx] - st) <= (0.5 * dt)\n",
        "    mask[idx[close]] = True\n",
        "    return mask\n",
        "\n",
        "\n",
        "def set_pupil_axis_nonnegative(figs):\n",
        "    \"\"\"Ensure the pupil (right) axis doesn't go below zero.\"\"\"\n",
        "    for fig in figs:\n",
        "        for ax in fig.get_axes():\n",
        "            label = (ax.get_ylabel() or \"\").lower()\n",
        "            if \"pupil\" in label:\n",
        "                ymin, ymax = ax.get_ylim()\n",
        "                ax.set_ylim(bottom=0, top=ymax)\n",
        "\n",
        "#main loop\n",
        "\n",
        "plt.ioff()\n",
        "total_saved = 0\n",
        "\n",
        "for rid in RAT_IDS:\n",
        "    rat_root = MODEL_ROOT / f\"Rat{rid}-Model-Outputs\"\n",
        "    h5_path  = HDF5_ROOT  / f\"Rat{rid}\" / H5_NAME\n",
        "\n",
        "    if not rat_root.exists():\n",
        "        print(f\"[Rat {rid}] model root missing — skipped\")\n",
        "        continue\n",
        "    if not h5_path.exists():\n",
        "        print(f\"[Rat {rid}] HDF5 missing — {h5_path}\")\n",
        "        continue\n",
        "\n",
        "    with h5py.File(h5_path, \"r\") as h5:\n",
        "        time_vec    = h5[\"time\"][...]\n",
        "        shock_times = h5[\"footshock_times\"][...]\n",
        "        pupil_full, pupil_key = load_pupil_from_h5(h5)\n",
        "\n",
        "    if pupil_full is None:\n",
        "        print(f\"[Rat {rid}] no pupil signal in HDF5 — skipped\")\n",
        "        continue\n",
        "    else:\n",
        "        print(f\"[Rat {rid}] pupil source: {pupil_key}\")\n",
        "\n",
        "    for suffix in MODEL_SUFFIXES:\n",
        "        model_dir = rat_root / f\"models_Rat{rid}_{suffix}\"\n",
        "        x_path    = model_dir / \"x_hat.npy\"\n",
        "        if not x_path.exists():\n",
        "            continue\n",
        "\n",
        "        try:\n",
        "            x_latents = np.load(x_path)  # (T, D)\n",
        "        except Exception as e:\n",
        "            print(f\"[Rat {rid}] {suffix:22s} failed to load x_hat ({type(e).__name__}: {e})\")\n",
        "            continue\n",
        "\n",
        "        T_lat, D = x_latents.shape\n",
        "\n",
        "        # match pupil & time to latents\n",
        "        if len(pupil_full) != len(time_vec):\n",
        "            pupil_full = pupil_full[:len(time_vec)]\n",
        "        if len(pupil_full) != T_lat:\n",
        "            f = interp1d(time_vec[:len(pupil_full)], pupil_full,\n",
        "                         kind=\"linear\", bounds_error=False, fill_value=\"extrapolate\")\n",
        "            time_use  = time_vec[:T_lat]\n",
        "            pupil_use = f(time_use)\n",
        "        else:\n",
        "            time_use  = time_vec[:T_lat]\n",
        "            pupil_use = pupil_full[:T_lat]\n",
        "\n",
        "        # footshock mask on the same grid\n",
        "        footshock_binary = build_footshock_mask(time_use, shock_times)\n",
        "\n",
        "        # RAW pupil (smoothed + clipped only; keep units)\n",
        "        pupil_proc = preprocess_pupil_raw(time_use, pupil_use)\n",
        "\n",
        "        duration = float(time_use[-1])\n",
        "\n",
        "        print(f\"[Rat {rid}] {suffix:22s} → plotting (T={T_lat}, D={D})\")\n",
        "\n",
        "        try:\n",
        "            figs = plot_latents_pupil_shocks(\n",
        "                x_latents=x_latents,\n",
        "                pupil_diameter=pupil_proc,\n",
        "                footshock_input=footshock_binary,\n",
        "                duration=duration,\n",
        "                integrate_latent=True,\n",
        "                smooth_sigma_lat_s=0.0,\n",
        "                pupil_smooth_sigma_s=0.0,\n",
        "                latent_color=\"black\",\n",
        "                pupil_color=\"tab:purple\",\n",
        "                figsize=FIGSIZE,\n",
        "                return_figs=True,\n",
        "            )\n",
        "        except Exception as e:\n",
        "            print(f\"[Rat {rid}] {suffix:22s} plotting error ({type(e).__name__}: {e})\")\n",
        "            traceback.print_exc(limit=1)\n",
        "            continue\n",
        "\n",
        "        # keep pupil axis non-negative , we can changehere\n",
        "        set_pupil_axis_nonnegative(figs)\n",
        "\n",
        "        out_dir = DEST_ROOT / f\"Rat{rid}\" / f\"models_Rat{rid}_{suffix}\"\n",
        "        out_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "        for k, fig in enumerate(figs, start=1):\n",
        "            fig.savefig(out_dir / f\"latent_vs_pupil_{k:02d}.png\", dpi=300, bbox_inches=\"tight\")\n",
        "            plt.close(fig)\n",
        "            total_saved += 1\n",
        "\n",
        "        print(f\"saved {len(figs)} PNG(s) → {out_dir}\")\n",
        "\n",
        "plt.ion()\n",
        "print(f\"\\nAll done. Saved {total_saved} PNG(s) under:\\n  {DEST_ROOT}\")"
      ],
      "metadata": {
        "id": "I1W77Y6DOt-z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This means that since we already have the old data and old runs and old runs outputs from the old models we can still keep them and test but we ll rerun the models with more discrete states so the new code is just for that change of directory."
      ],
      "metadata": {
        "id": "FEUaKYbTTfIU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plot Discrete States ( With 2 different styles for now )"
      ],
      "metadata": {
        "id": "jev3p7ax29x2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Compatible with the old model runs and the old data on drive"
      ],
      "metadata": {
        "id": "OG0PWlNqUJYQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "RAT_IDS        = [3,4,8,10,11,13,14,15,16,17,18,19,20,21]\n",
        "MODEL_SUFFIXES = [\n",
        "    \"ventral_responsive\",\"ventral\",\n",
        "    \"dorsal_responsive\",\"dorsal\",\n",
        "    \"responsive_all\",\n",
        "    \"thalamus_responsive\",\"thalamus\",\n",
        "]\n",
        "\n",
        "MODEL_ROOT     = Path(\"/content/drive/My Drive/rSLDS/rSLDS-Model-Outputs\")\n",
        "CSV_AREA_ROOT  = Path(\"/content/drive/My Drive/rSLDS/Sub-Data/Seperate-by-Area\")\n",
        "CSV_RESP_ROOT  = Path(\"/content/drive/My Drive/rSLDS/Sub-Data/Only-Responsive\")\n",
        "DEST_ROOT      = Path(\"/content/drive/My Drive/rSLDS/All-Plots/discrete_states_both\")\n",
        "\n",
        "def area_subset_from_suffix(sfx: str):\n",
        "    s = sfx.lower()\n",
        "    # special-case the combined run\n",
        "    if s == \"responsive_all\":\n",
        "        return None, \"responsive_all\"\n",
        "    area = \"ventral\"  if s.startswith(\"ventral\")  else \\\n",
        "           \"dorsal\"   if s.startswith(\"dorsal\")   else \\\n",
        "           \"thalamus\" if s.startswith(\"thalamus\") else None\n",
        "    if area is None:\n",
        "        raise ValueError(f\"Bad suffix: {sfx}\")\n",
        "    if   \"responsive\" in s: subset = \"responsive\"\n",
        "    else:                    subset = \"allActive\"\n",
        "    return area, subset\n",
        "\n",
        "plt.ioff()\n",
        "\n",
        "for rid in RAT_IDS:\n",
        "    rat_root = MODEL_ROOT / f\"Rat{rid}-Model-Outputs\"\n",
        "    if not rat_root.exists():\n",
        "        print(f\"[Rat {rid}] root folder missing — skipped\")\n",
        "        continue\n",
        "\n",
        "    for suffix in MODEL_SUFFIXES:\n",
        "        model_sub = f\"models_Rat{rid}_{suffix}\"\n",
        "        model_dir = rat_root / model_sub\n",
        "\n",
        "        z_file     = model_dir / \"z_hat.npy\"\n",
        "        shock_file = model_dir / \"footshock.npy\"\n",
        "        if not (z_file.exists() and shock_file.exists()):\n",
        "            continue\n",
        "\n",
        "        try:\n",
        "            AREA, SUBSET = area_subset_from_suffix(suffix)\n",
        "        except ValueError:\n",
        "            print(f\"[Rat {rid}] {suffix:22s}  bad suffix — skipped\")\n",
        "            continue\n",
        "\n",
        "        # pick the correct CSV path\n",
        "        if AREA is None and SUBSET == \"responsive_all\":\n",
        "            csv_path = (CSV_RESP_ROOT / f\"Rat{rid}\" /\n",
        "                        f\"area_splits_rat{rid}_responsive\" / \"responsive_rates_raw.csv\")\n",
        "        else:\n",
        "            csv_path = (CSV_AREA_ROOT / f\"Rat{rid}\" /\n",
        "                        f\"area_splits_rat{rid}_{SUBSET}\" / f\"{AREA}_wide.csv\")\n",
        "\n",
        "        if not csv_path.exists():\n",
        "            print(f\"[Rat {rid}] {suffix:22s}  CSV missing — skipped ({csv_path})\")\n",
        "            continue\n",
        "\n",
        "        # load\n",
        "        try:\n",
        "            z_states      = np.load(z_file)\n",
        "            footshock_vec = np.load(shock_file)\n",
        "            time_vec      = pd.read_csv(csv_path, usecols=[\"time_s\"])[\"time_s\"].values\n",
        "        except Exception as e:\n",
        "            print(f\"[Rat {rid}] {suffix:22s}  load error: {e}\")\n",
        "            traceback.print_exc(limit=1)\n",
        "            continue\n",
        "\n",
        "        if not (len(z_states) == len(time_vec) == len(footshock_vec)):\n",
        "            print(f\"[Rat {rid}] {suffix:22s}  length mismatch — skipped\")\n",
        "            continue\n",
        "\n",
        "        out_dir = DEST_ROOT / f\"Rat{rid}\" / model_sub\n",
        "        out_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "        title_area = \"responsive_all\" if AREA is None else AREA\n",
        "\n",
        "        # style 1\n",
        "        try:\n",
        "            fig1, _ = plot_discrete_states(\n",
        "                z_states      = z_states,\n",
        "                time_vec      = time_vec,\n",
        "                shock_times   = footshock_vec,\n",
        "                palette       = \"Set1\",\n",
        "                lw            = 6,\n",
        "                min_duration  = 0.5,\n",
        "                dot_style     = \"line\",\n",
        "                title         = f\"Rat {rid} – {title_area} – discrete states (style 1)\",\n",
        "                figsize       = (12, 2.5),\n",
        "            )\n",
        "            fig1.savefig(out_dir / \"states_style1.png\", dpi=300, bbox_inches=\"tight\")\n",
        "            plt.close(fig1)\n",
        "        except Exception as e:\n",
        "            print(f\"[Rat {rid}] {suffix:22s}  style1 failed: {e}\")\n",
        "            traceback.print_exc(limit=1)\n",
        "\n",
        "        # style 2\n",
        "        try:\n",
        "            plot_discrete_states2(\n",
        "                z_states      = z_states,\n",
        "                time_vec      = time_vec,\n",
        "                shock_times   = footshock_vec,\n",
        "                palette       = \"Set1\",\n",
        "                lw            = 6,\n",
        "                title         = f\"Rat {rid} – {title_area} – discrete states (style 2)\",\n",
        "                figsize       = (12, 2.5),\n",
        "            )\n",
        "            fig2 = plt.gcf()\n",
        "            fig2.savefig(out_dir / \"states_style2.png\", dpi=300, bbox_inches=\"tight\")\n",
        "            plt.close(fig2)\n",
        "        except Exception as e:\n",
        "            print(f\"[Rat {rid}] {suffix:22s}  style2 failed: {e}\")\n",
        "            traceback.print_exc(limit=1)\n",
        "\n",
        "        print(f\"[Rat {rid}] {suffix:22s} saved → {out_dir}\")\n",
        "\n",
        "plt.ion()\n"
      ],
      "metadata": {
        "id": "2HXI0ScD-kuX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Switch Statistics"
      ],
      "metadata": {
        "id": "Zeejp-C6tqsP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Shows discrete state switching statitsics for pre shock and after shock observation. How the states changes between each other happen and its statistics."
      ],
      "metadata": {
        "id": "yNdcb-5RTS_m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Compatible with the old model runs and the old data on drive"
      ],
      "metadata": {
        "id": "VY5g-PVhUvrC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "RAT_IDS        = [3, 4, 8, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21]\n",
        "MODEL_SUFFIXES = [\n",
        "    \"ventral_responsive\",\"ventral\",\n",
        "    \"dorsal_responsive\",\"dorsal\",\n",
        "    \"responsive_all\",\n",
        "    \"thalamus_responsive\",\"thalamus\",\n",
        "]\n",
        "\n",
        "MODEL_ROOT     = Path(\"/content/drive/My Drive/rSLDS/rSLDS-Model-Outputs\")\n",
        "CSV_AREA_ROOT  = Path(\"/content/drive/My Drive/rSLDS/Sub-Data/Seperate-by-Area\")\n",
        "CSV_RESP_ROOT  = Path(\"/content/drive/My Drive/rSLDS/Sub-Data/Only-Responsive\")\n",
        "DEST_ROOT      = Path(\"/content/drive/My Drive/rSLDS/All-Plots/switch_summary\")\n",
        "\n",
        "def area_subset_from_suffix(sfx: str):\n",
        "    s = sfx.lower()\n",
        "    if s == \"responsive_all\":\n",
        "        return None, \"responsive_all\"\n",
        "    area = \"ventral\"  if s.startswith(\"ventral\")  else \\\n",
        "           \"dorsal\"   if s.startswith(\"dorsal\")   else \\\n",
        "           \"thalamus\" if s.startswith(\"thalamus\") else None\n",
        "    if area is None:\n",
        "        raise ValueError(f\"cannot infer area from suffix {sfx!r}\")\n",
        "    subset = \"responsive\" if \"responsive\" in s else \"allActive\"\n",
        "    return area, subset\n",
        "\n",
        "plt.ioff()\n",
        "\n",
        "for rid in RAT_IDS:\n",
        "    rat_root = MODEL_ROOT / f\"Rat{rid}-Model-Outputs\"\n",
        "    if not rat_root.exists():\n",
        "        print(f\"[Rat {rid:2d}] root folder missing – skipped.\")\n",
        "        continue\n",
        "\n",
        "    for suffix in MODEL_SUFFIXES:\n",
        "        model_sub  = f\"models_Rat{rid}_{suffix}\"\n",
        "        model_dir  = rat_root / model_sub\n",
        "        z_file     = model_dir / \"z_hat.npy\"\n",
        "        shock_file = model_dir / \"footshock.npy\"\n",
        "\n",
        "        if not (z_file.exists() and shock_file.exists()):\n",
        "            continue\n",
        "\n",
        "        try:\n",
        "            AREA, SUBSET = area_subset_from_suffix(suffix)\n",
        "        except ValueError:\n",
        "            print(f\"[Rat {rid:2d}] {suffix:24s} – bad suffix\")\n",
        "            continue\n",
        "\n",
        "        # pick the correct CSV path\n",
        "        if AREA is None and SUBSET == \"responsive_all\":\n",
        "            csv_path = (CSV_RESP_ROOT / f\"Rat{rid}\" /\n",
        "                        f\"area_splits_rat{rid}_responsive\" / \"responsive_rates_raw.csv\")\n",
        "        else:\n",
        "            csv_path = (CSV_AREA_ROOT / f\"Rat{rid}\" /\n",
        "                        f\"area_splits_rat{rid}_{SUBSET}\" / f\"{AREA}_wide.csv\")\n",
        "\n",
        "        if not csv_path.exists():\n",
        "            print(f\"[Rat {rid:2d}] {suffix:24s} – CSV missing: {csv_path}\")\n",
        "            continue\n",
        "\n",
        "        # load\n",
        "        try:\n",
        "            z_states      = np.load(z_file).astype(int).ravel()\n",
        "            footshock_vec = np.load(shock_file).squeeze()  # could be (T,1) or (T,)\n",
        "            df            = pd.read_csv(csv_path)\n",
        "            # prefer 'time_s' but fall back to the first time-like column if needed\n",
        "            time_col = \"time_s\" if \"time_s\" in df.columns else df.columns[0]\n",
        "            time_vec      = df[time_col].to_numpy()\n",
        "        except Exception as e:\n",
        "            print(f\"[Rat {rid:2d}] {suffix:24s} – load error ({e})\")\n",
        "            traceback.print_exc(limit=1)\n",
        "            continue\n",
        "\n",
        "        if not (len(z_states)==len(time_vec)==len(footshock_vec)):\n",
        "            print(f\"[Rat {rid:2d}] {suffix:24s} – length mismatch \"\n",
        "                  f\"(z={len(z_states)}, t={len(time_vec)}, shock={len(footshock_vec)})\")\n",
        "            continue\n",
        "\n",
        "        out_dir = DEST_ROOT / f\"Rat{rid}\" / model_sub\n",
        "        out_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "        # run summary plots\n",
        "        try:\n",
        "            stats, figs = plot_switch_summary(\n",
        "                z_states       = z_states,\n",
        "                time_vec       = time_vec,\n",
        "                footshock_mask = footshock_vec.astype(bool),\n",
        "                separate       = True,   # returns 3 figs\n",
        "                dpi            = 150,\n",
        "            )\n",
        "        except Exception as e:\n",
        "            print(f\"[Rat {rid:2d}] {suffix:24s} – plot error ({e})\")\n",
        "            traceback.print_exc(limit=1)\n",
        "            continue\n",
        "\n",
        "        # save figures\n",
        "        label_map = [\"switch_count\", \"switch_rate\", \"switch_occupancy\"]\n",
        "        for tag, fig in zip(label_map, figs):\n",
        "            fig.savefig(out_dir / f\"{tag}.png\", dpi=300, bbox_inches=\"tight\")\n",
        "            plt.close(fig)\n",
        "\n",
        "        # optionally save stats as CSV if it's a dict/DataFrame-like\n",
        "        try:\n",
        "            import pandas as pd\n",
        "            if hasattr(stats, \"to_csv\"):\n",
        "                stats.to_csv(out_dir / \"switch_stats.csv\", index=False)\n",
        "            elif isinstance(stats, dict):\n",
        "                pd.DataFrame([stats]).to_csv(out_dir / \"switch_stats.csv\", index=False)\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "        print(f\"[Rat {rid:2d}] {suffix:24s} ✓  saved in {out_dir}\")\n",
        "\n",
        "plt.ion()\n"
      ],
      "metadata": {
        "id": "A5u8tWtNDdDD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Mutual Information Latents / Pupil/ Speed"
      ],
      "metadata": {
        "id": "V4prhDAQYUUn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mutual Information Criterion between latent dimensions and speed. The amount of information one random variable contains about another. How much knowing one variable reduces the uncertainty about the oter variable. Related to the concept entropy which is a measure of uncertainty or randomness in a single random variable. Mutual Information (MI): The difference between the entropy of one variable and its conditional entropy given another variable. It quantifies how much knowing one variable reduces the uncertainty of the other."
      ],
      "metadata": {
        "id": "csFfOBMjTgLD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Compatible with the old model runs and the old data on drive"
      ],
      "metadata": {
        "id": "nqGPQUEEXtdj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**How to read the output?**\n",
        "dim → which latent dimension.\n",
        "\n",
        "MI_raw → how much info (mutual information) that latent has with speed.\n",
        "\n",
        "thr95 → the “95% cutoff” from shuffled data (the null).\n",
        "\n",
        "p → how often shuffles were as strong as the real data (a p-value).\n",
        "\n",
        "Red star = significant\n",
        "\n",
        "Different shuffle types exist:\n",
        "\n",
        "circular → shift the signal in time,\n",
        "\n",
        "strict → scramble phases but keep spectrum,\n",
        "\n",
        "permute → fully random.\n",
        "\n",
        "we can chose which one with SHUFFLE_METHOD, and how many times with N_SHUFFLE.\n",
        "here i m shuffling the behavioural signals.\n"
      ],
      "metadata": {
        "id": "YMz4UjetX_EX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "import numpy as np, pandas as pd, matplotlib.pyplot as plt, traceback\n",
        "\n",
        "# make sure latent_signal_mi is available:\n",
        "from mutual_information import latent_signal_mi\n",
        "\n",
        "RAT_IDS        = [3, 4, 8, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21]\n",
        "MODEL_SUFFIXES = [\n",
        "    \"ventral_responsive\",\"ventral\",\n",
        "    \"dorsal_responsive\",\"dorsal\",\n",
        "    \"responsive_all\",\n",
        "    \"thalamus_responsive\",\"thalamus\",\n",
        "]\n",
        "\n",
        "MODEL_ROOT     = Path(\"/content/drive/My Drive/rSLDS/rSLDS-Model-Outputs\")\n",
        "CSV_AREA_ROOT  = Path(\"/content/drive/My Drive/rSLDS/Sub-Data/Seperate-by-Area\")\n",
        "CSV_RESP_ROOT  = Path(\"/content/drive/My Drive/rSLDS/Sub-Data/Only-Responsive\")\n",
        "DEST_BASE      = Path(\"/content/drive/My Drive/rSLDS/All-Plots\")\n",
        "\n",
        "WIN_S             = 0.5\n",
        "INTEGRATE_LATENTS = False\n",
        "SHUFFLE_METHOD    = \"permute\"      # \"circular\"|\"strict\"|\"permute\"\n",
        "N_SHUFFLE         = 1000\n",
        "FDR_ALPHA         = 0.05\n",
        "RNG_SEED          = 0\n",
        "\n",
        "# helpers\n",
        "def area_subset_from_suffix(sfx: str):\n",
        "    s = sfx.lower()\n",
        "    if s == \"responsive_all\":\n",
        "        return None, \"responsive_all\"\n",
        "    area = \"ventral\"  if s.startswith(\"ventral\")  else \\\n",
        "           \"dorsal\"   if s.startswith(\"dorsal\")   else \\\n",
        "           \"thalamus\" if s.startswith(\"thalamus\") else None\n",
        "    if area is None:\n",
        "        raise ValueError(f\"cannot infer area from suffix {sfx!r}\")\n",
        "    subset = \"responsive\" if \"responsive\" in s else \"allActive\"\n",
        "    return area, subset\n",
        "\n",
        "def get_pupil_from_csv(df: pd.DataFrame):\n",
        "    for col in (\"pupil\", \"pupil_diameter\", \"pupil_size\"):\n",
        "        if col in df.columns:\n",
        "            return df[col].to_numpy()\n",
        "    return None\n",
        "\n",
        "def get_speed_from_csv(df: pd.DataFrame):\n",
        "    if \"speed\" in df.columns:\n",
        "        return df[\"speed\"].to_numpy()\n",
        "    for cand in (\"velocity\",\"speed_cm_s\",\"beh_speed\"):\n",
        "        if cand in df.columns:\n",
        "            return df[cand].to_numpy()\n",
        "    return None\n",
        "\n",
        "\n",
        "for rid in RAT_IDS:\n",
        "    rat_root = MODEL_ROOT / f\"Rat{rid}-Model-Outputs\"\n",
        "    if not rat_root.exists():\n",
        "        print(f\"[Rat {rid:2d}] root folder missing\")\n",
        "        continue\n",
        "\n",
        "    for suffix in MODEL_SUFFIXES:\n",
        "        model_sub = f\"models_Rat{rid}_{suffix}\"\n",
        "        model_dir = rat_root / model_sub\n",
        "\n",
        "        x_file    = model_dir / \"x_hat.npy\"\n",
        "        speed_npy = model_dir / \"speed.npy\"\n",
        "        pupil_npy = model_dir / \"pupil.npy\"\n",
        "\n",
        "        # figure out which CSV to use\n",
        "        try:\n",
        "            AREA, SUBSET = area_subset_from_suffix(suffix)\n",
        "        except ValueError:\n",
        "            continue\n",
        "\n",
        "        if AREA is None and SUBSET == \"responsive_all\":\n",
        "            csv_path = (CSV_RESP_ROOT / f\"Rat{rid}\" /\n",
        "                        f\"area_splits_rat{rid}_responsive\" / \"responsive_rates_raw.csv\")\n",
        "        else:\n",
        "            csv_path = (CSV_AREA_ROOT / f\"Rat{rid}\" /\n",
        "                        f\"area_splits_rat{rid}_{SUBSET}\" / f\"{AREA}_wide.csv\")\n",
        "\n",
        "        if not (x_file.exists() and csv_path.exists()):\n",
        "            continue\n",
        "\n",
        "        try:\n",
        "            x_latents = np.load(x_file)\n",
        "            df_csv    = pd.read_csv(csv_path)\n",
        "\n",
        "            # time column\n",
        "            time_col  = \"time_s\" if \"time_s\" in df_csv.columns else df_csv.columns[0]\n",
        "            time_vec  = df_csv[time_col].to_numpy()\n",
        "\n",
        "            # speed\n",
        "            if speed_npy.exists():\n",
        "                speed = np.load(speed_npy)\n",
        "            else:\n",
        "                speed = get_speed_from_csv(df_csv)\n",
        "\n",
        "            # pupil\n",
        "            if pupil_npy.exists():\n",
        "                pupil = np.load(pupil_npy)\n",
        "            else:\n",
        "                pupil = get_pupil_from_csv(df_csv)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"[Rat {rid:2d}] {suffix:24s} – load error ({e})\")\n",
        "            traceback.print_exc(limit=1)\n",
        "            continue\n",
        "\n",
        "        # pack available signals\n",
        "        signals = {}\n",
        "        if speed is not None: signals[\"speed\"] = speed\n",
        "        if pupil is not None: signals[\"pupil\"] = pupil\n",
        "        if not signals:\n",
        "            print(f\"[Rat {rid:2d}] {suffix:24s} – no speed/pupil found\")\n",
        "            continue\n",
        "\n",
        "        for sig_name, sig in signals.items():\n",
        "            if not (len(x_latents) == len(sig) == len(time_vec)):\n",
        "                print(f\"[Rat {rid:2d}] {suffix:24s} – length mismatch ({sig_name})\")\n",
        "                continue\n",
        "\n",
        "            sig_clean = np.nan_to_num(sig, nan=np.nanmean(sig))\n",
        "\n",
        "            # === MI with rich output (includes null mean, MI_delta, p_perm, FDR) ===\n",
        "            mi_rec = latent_signal_mi(\n",
        "                latents           = x_latents,\n",
        "                signal            = sig_clean,\n",
        "                time_vec          = time_vec,\n",
        "                win_s             = WIN_S,\n",
        "                integrate_latents = INTEGRATE_LATENTS,\n",
        "                shuffle           = SHUFFLE_METHOD,\n",
        "                n_shuffle         = N_SHUFFLE,\n",
        "                random_state      = RNG_SEED,\n",
        "                return_rich       = True,\n",
        "                fdr_alpha         = FDR_ALPHA,\n",
        "            )\n",
        "\n",
        "            df_mi = pd.DataFrame.from_records(mi_rec)\n",
        "\n",
        "            # add metadata about the run so it's traceable\n",
        "            df_mi[\"shuffle\"]           = SHUFFLE_METHOD\n",
        "            df_mi[\"n_shuffle\"]         = N_SHUFFLE\n",
        "            df_mi[\"win_s\"]             = WIN_S\n",
        "            df_mi[\"integrate_latents\"] = INTEGRATE_LATENTS\n",
        "            df_mi[\"rat\"]               = rid\n",
        "            df_mi[\"model_sub\"]         = model_sub\n",
        "            df_mi[\"signal\"]            = sig_name\n",
        "\n",
        "            # where to save\n",
        "            DEST_ROOT = DEST_BASE / f\"mi_{sig_name}\"\n",
        "            out_dir   = DEST_ROOT / f\"Rat{rid}\" / model_sub\n",
        "            out_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "            # save CSV (now includes MI_null_mean and MI_delta = MI_raw - MI_null_mean)\n",
        "            df_mi.to_csv(out_dir / f\"mi_latents_{sig_name}.csv\", index=False)\n",
        "\n",
        "            dims = df_mi[\"dim\"].to_numpy()\n",
        "            mi_vals = df_mi[\"MI_raw\"].to_numpy()\n",
        "\n",
        "            fig, ax = plt.subplots(figsize=(0.65*len(dims)+3, 3))\n",
        "            ax.bar(dims, mi_vals, color=\"tab:blue\", alpha=.85)\n",
        "\n",
        "            # prefer FDR decision if present; else p_perm<.05; else nothing\n",
        "            star_mask = None\n",
        "            star_label = None\n",
        "            if \"reject_bh\" in df_mi.columns and df_mi[\"reject_bh\"].any():\n",
        "                star_mask  = df_mi[\"reject_bh\"].to_numpy().astype(bool)\n",
        "                star_label = f\"FDR q ≤ {FDR_ALPHA:g}\"\n",
        "            elif \"p_perm\" in df_mi.columns:\n",
        "                star_mask  = (df_mi[\"p_perm\"].to_numpy() < 0.05)\n",
        "                star_label = \"p_perm < .05\"\n",
        "\n",
        "            if star_mask is not None and star_mask.any():\n",
        "                offset = 0.02 * (mi_vals.max() if np.isfinite(mi_vals.max()) and mi_vals.max() > 0 else 1.0)\n",
        "                ax.scatter(dims[star_mask], (mi_vals + offset)[star_mask],\n",
        "                           marker=\"*\", color=\"red\", zorder=3, label=star_label)\n",
        "                ax.legend(frameon=False)\n",
        "\n",
        "            ax.set_xlabel(\"latent dim\")\n",
        "            ax.set_ylabel(\"MI (bits)\")\n",
        "            ax.set_title(f\"Rat {rid} – {suffix}  ({sig_name} vs. latents)\\n\"\n",
        "                         f\"ΔMI = MI_raw − mean(null), shuffle={SHUFFLE_METHOD}, n={N_SHUFFLE}\")\n",
        "            fig.tight_layout()\n",
        "            fig.savefig(out_dir / f\"mi_bar_{sig_name}.png\", dpi=300, bbox_inches=\"tight\")\n",
        "            plt.close(fig)\n",
        "\n",
        "            print(f\"[Rat {rid:2d}] {suffix:24s} ✓  MI({sig_name}) → {out_dir}\")\n"
      ],
      "metadata": {
        "id": "HV_D6gPcYTzS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "dim – latent index 0 = first latent.\n",
        "\n",
        "MI_raw – MI between this latent and the behavior on real (unshuffled) data.\n",
        "Example: 0.0316.\n",
        "\n",
        "MI_null_mean / MI_null_std – average and SD of MI under the null.\n",
        "Example: null mean 0.00547, SD 0.00800.\n",
        "\n",
        "MI_delta – how much larger the real MI is than the null mean: MI_raw − MI_null_mean.\n",
        "\n",
        "\n",
        "thr95 – the 95th percentile of the null; a simple “uncorrected” threshold.\n",
        "\n",
        "\n",
        "z – z-score: (MI_raw − MI_null_mean) / MI_null_std.\n",
        "\n",
        "p_perm – permutation p-value: fraction of null ≥ real (with +1 correction).\n",
        "\n",
        "significant_95 – TRUE if MI_raw > thr95 (uncorrected, per-dim).\n",
        "\n",
        "q_bh / reject_bh – Benjamini–Hochberg FDR across dims; reject_bh says whether it’s significant after multiple-comparisons at your FDR_ALPHA (0.05).\n",
        "\n",
        "shuffle, n_shuffle – how the null was built (permute) and how many surrogates (1000).\n",
        "\n",
        "win_s, integrate_latents – MI computed on 0.5 s windows; FALSE means raw latents (not integrated).\n",
        "\n",
        "rat, model_sub, signal – provenance (which animal, run folder, and behavior)."
      ],
      "metadata": {
        "id": "4uc2vlW5dB64"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## MI Pre-Post Shock"
      ],
      "metadata": {
        "id": "sVx3_Ojfvy2L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In order to see the mutual information  pre /post shock observation with the external inputs pupil and speed."
      ],
      "metadata": {
        "id": "wRjaz48WcCY6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Compatible with the old model runs and the old data on drive"
      ],
      "metadata": {
        "id": "rxI_OtlXYsqu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**How to read it ?**\n",
        "\n",
        "Blue bar = MI(latent d, behaviour) before the first shock.\n",
        "\n",
        "Red bar = MI after the first shock.\n",
        "\n",
        "Red star (★) on a red bar = that post-shock MI is significant vs the shuffled-null (either p < .05 or above the null’s 95th percentile, depending on the script title).\n",
        "\n",
        "Higher bar ⇒ stronger relationship (in bits) between that latent and the behaviour in that segment.\n",
        "dim – latent index.\n",
        "\n",
        "MI_raw – the measured MI (bits) between that latent (windowed) and the behaviour.\n",
        "\n",
        "MI_min – minimum MI from the shuffled null (mostly for reference; you can ignore).\n",
        "\n",
        "thr95 – the 95th percentile of the null MI (the “significance threshold”).\n",
        "\n",
        "p – permutation p-value: fraction of shuffled MI ≥ MI_raw (smaller = more significant)."
      ],
      "metadata": {
        "id": "gBheeFOgg_7D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "import numpy as np, pandas as pd, matplotlib.pyplot as plt, traceback, h5py\n",
        "\n",
        "RAT_IDS        = [3,4,8,10,11,13,14,15,16,17,18,19,20,21]\n",
        "MODEL_SUFFIXES = [\n",
        "    \"ventral_responsive\",\"ventral\",\n",
        "    \"dorsal_responsive\",\"dorsal\",\n",
        "    \"responsive_all\",\n",
        "    \"thalamus_responsive\",\"thalamus\",\n",
        "]\n",
        "\n",
        "MODEL_ROOT = Path(\"/content/drive/My Drive/rSLDS/rSLDS-Model-Outputs\")\n",
        "CSV_AREA_ROOT = Path(\"/content/drive/My Drive/rSLDS/Sub-Data/Seperate-by-Area\")\n",
        "CSV_RESP_ROOT = Path(\"/content/drive/My Drive/rSLDS/Sub-Data/Only-Responsive\")\n",
        "H5_ROOT   = Path(\"/content/drive/My Drive/rSLDS/Rat-Data-hdf5\")\n",
        "DEST_ROOT = Path(\"/content/drive/My Drive/rSLDS/All-Plots/mi_prepost\")\n",
        "\n",
        "def area_subset_from_suffix(sfx: str):\n",
        "    s = sfx.lower()\n",
        "    if s == \"responsive_all\":\n",
        "        return None, \"responsive_all\"\n",
        "    area = \"ventral\"  if s.startswith(\"ventral\")  else \\\n",
        "           \"dorsal\"   if s.startswith(\"dorsal\")   else \\\n",
        "           \"thalamus\" if s.startswith(\"thalamus\") else None\n",
        "    if area is None:\n",
        "        raise ValueError(f\"Bad suffix: {sfx}\")\n",
        "    subset = \"responsive\" if \"responsive\" in s else \"allActive\"\n",
        "    return area, subset\n",
        "\n",
        "def normalize_footshock_mask(time_vec: np.ndarray, footshock) -> np.ndarray:\n",
        "    t  = np.asarray(time_vec, float).ravel()\n",
        "    fs = np.asarray(footshock).ravel()\n",
        "    T  = len(t); mask = np.zeros(T, dtype=bool)\n",
        "    if fs.size == T: return fs.astype(bool)\n",
        "    if np.issubdtype(fs.dtype, np.integer):\n",
        "        idx = fs[(fs >= 0) & (fs < T)].astype(int); mask[idx] = True; return mask\n",
        "    ts = fs.astype(float); ts = ts[(ts >= t[0]) & (ts <= t[-1])]\n",
        "    if ts.size == 0: return mask\n",
        "    idx = np.searchsorted(t, ts, side=\"left\"); idx = np.clip(idx, 0, T-1)\n",
        "    dt = float(np.median(np.diff(t))); close = np.abs(t[idx] - ts) <= (0.5 * dt)\n",
        "    if close.size == idx.size: idx = idx[close]\n",
        "    mask[idx] = True; return mask\n",
        "\n",
        "def load_signal_h5_or_csv(rid: int, df: pd.DataFrame, key_candidates_h5, key_candidates_csv):\n",
        "    \"\"\"Try HDF5 first (preferred), then CSV. Returns np.ndarray or None.\"\"\"\n",
        "    h5_path = H5_ROOT / f\"Rat{rid}\" / \"NpxFiringRate_Behavior_SBL_10msBINS_0smoothing.hdf5\"\n",
        "    if h5_path.exists():\n",
        "        try:\n",
        "            with h5py.File(h5_path, \"r\") as h5:\n",
        "                for k in key_candidates_h5:\n",
        "                    if k in h5:\n",
        "                        return np.asarray(h5[k][...]).squeeze()\n",
        "        except Exception as e:\n",
        "            print(f\"[Rat {rid}] HDF5 read error ({e})\")\n",
        "    for c in key_candidates_csv:\n",
        "        if c in df.columns:\n",
        "            return df[c].to_numpy()\n",
        "    return None\n",
        "\n",
        "for rid in RAT_IDS:\n",
        "    rat_root = MODEL_ROOT / f\"Rat{rid}-Model-Outputs\"\n",
        "    if not rat_root.exists():\n",
        "        print(f\"[Rat {rid}]   couldnt \")\n",
        "        continue\n",
        "\n",
        "    for suffix in MODEL_SUFFIXES:\n",
        "        model_sub  = f\"models_Rat{rid}_{suffix}\"\n",
        "        model_dir  = rat_root / model_sub\n",
        "\n",
        "        x_file     = model_dir / \"x_hat.npy\"\n",
        "        shock_file = model_dir / \"footshock.npy\"\n",
        "        if not (x_file.exists() and shock_file.exists()):\n",
        "            continue\n",
        "\n",
        "        try:\n",
        "            AREA, SUBSET = area_subset_from_suffix(suffix)\n",
        "        except ValueError:\n",
        "            print(f\"[Rat {rid}] {suffix:22s}  bad suffix – skipped\")\n",
        "            continue\n",
        "\n",
        "        # choose the correct CSV path\n",
        "        if AREA is None and SUBSET == \"responsive_all\":\n",
        "            csv_path = (CSV_RESP_ROOT / f\"Rat{rid}\" /\n",
        "                        f\"area_splits_rat{rid}_responsive\" / \"responsive_rates_raw.csv\")\n",
        "        else:\n",
        "            csv_path = (CSV_AREA_ROOT / f\"Rat{rid}\" /\n",
        "                        f\"area_splits_rat{rid}_{SUBSET}\" / f\"{AREA}_wide.csv\")\n",
        "        if not csv_path.exists():\n",
        "            print(f\"[Rat {rid}] {suffix:22s}  CSV missing – skipped\")\n",
        "            continue\n",
        "\n",
        "        # load shared\n",
        "        try:\n",
        "            latents       = np.load(x_file)               # (T,D)\n",
        "            footshock_vec = np.load(shock_file)           # mask/idx/ts\n",
        "            df            = pd.read_csv(csv_path)\n",
        "            time_col      = \"time_s\" if \"time_s\" in df.columns else df.columns[0]\n",
        "            time_vec      = df[time_col].to_numpy()\n",
        "\n",
        "            speed = load_signal_h5_or_csv(\n",
        "                rid, df,\n",
        "                key_candidates_h5=[\"speed\", \"behavior/speed\"],\n",
        "                key_candidates_csv=[\"speed\", \"velocity\", \"speed_cm_s\", \"beh_speed\"]\n",
        "            )\n",
        "            pupil = load_signal_h5_or_csv(\n",
        "                rid, df,\n",
        "                key_candidates_h5=[\"pupil\", \"pupil_diameter\", \"behavior/pupil\"],\n",
        "                key_candidates_csv=[\"pupil\", \"pupil_diameter\", \"pupil_size\"]\n",
        "            )\n",
        "        except Exception as e:\n",
        "            print(f\"[Rat {rid}] {suffix:22s}  load error ({e})\")\n",
        "            traceback.print_exc(limit=1)\n",
        "            continue\n",
        "\n",
        "        fs_mask = normalize_footshock_mask(time_vec, footshock_vec)\n",
        "        if not fs_mask.any():\n",
        "            print(f\"[Rat {rid}] {suffix:22s}  (no shock found) – skipped\")\n",
        "            continue\n",
        "\n",
        "        signals = {\"speed\": speed, \"pupil\": pupil}\n",
        "        for sig_name, sig in signals.items():\n",
        "            if sig is None:\n",
        "                print(f\"[Rat {rid}] {suffix:22s}  no {sig_name} in HDF5/CSV – skipped\")\n",
        "                continue\n",
        "            if not (len(latents) == len(sig) == len(time_vec)):\n",
        "                print(f\"[Rat {rid}] {suffix:22s}  length mismatch ({sig_name}) – skipped\")\n",
        "                continue\n",
        "\n",
        "            sig_clean = np.nan_to_num(sig, nan=float(np.nanmean(sig)))\n",
        "\n",
        "            print(f\"[Rat {rid}] {suffix:22s}  → MI pre/post ({sig_name}) …\")\n",
        "            try:\n",
        "                table, fig = mi_pre_post_plot(\n",
        "                    latents           = latents,\n",
        "                    signal            = sig_clean,\n",
        "                    time_vec          = time_vec,\n",
        "                    footshock_mask    = fs_mask,\n",
        "                    win_s             = 0.3,\n",
        "                    integrate_latents = False,\n",
        "                    shuffle           = \"permute\",\n",
        "                    n_shuffle         = 1000,\n",
        "                    color_pre         = \"#38588C\",\n",
        "                    color_post        = \"#D73027\",\n",
        "                )\n",
        "            except Exception as e:\n",
        "                print(f\" MI failed ({sig_name}) ({e.__class__.__name__}: {e})\")\n",
        "                traceback.print_exc(limit=1)\n",
        "                continue\n",
        "\n",
        "            out_dir = DEST_ROOT / f\"Rat{rid}\" / model_sub\n",
        "            out_dir.mkdir(parents=True, exist_ok=True)\n",
        "            table.to_csv(out_dir / f\"MI_pre_post_{sig_name}.csv\", index=False)\n",
        "            fig.savefig(out_dir / f\"MI_pre_post_{sig_name}.png\", dpi=300, bbox_inches=\"tight\")\n",
        "            plt.close(fig)\n",
        "            print(f\"saved → {out_dir} ({sig_name})\")\n"
      ],
      "metadata": {
        "id": "gzydmvztdWZI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## State Vector Field"
      ],
      "metadata": {
        "id": "3T5onl3typ6p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Each rSLDS state has its own dynamics model (rules for how latent activity changes over time).\n",
        "\n",
        "A vector field is a map of arrows in latent space:\n",
        "\n",
        "Each arrow shows the direction and speed of change in neural activity if the system is at that point.\n",
        "\n",
        "This lets us see how brain activity evolves differently across states:\n",
        "\n",
        "Some states may stabilize activity (arrows pointing inward).\n",
        "\n",
        "Others may create rotations or oscillations (arrows circling around).\n",
        "\n",
        "In short, vector fields visualize the “flow of neural population activity” under each discrete state."
      ],
      "metadata": {
        "id": "8DWJDD16mevE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Compatible with the old model runs and the old data on drive"
      ],
      "metadata": {
        "id": "drl7S94odsPp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "RAT_IDS        = [3,4,8,10,11,13,14,15,16,17,18,19,20,21]\n",
        "MODEL_SUFFIXES = [\n",
        "    \"ventral_responsive\",\"ventral\",\n",
        "    \"dorsal_responsive\",\"dorsal\",\n",
        "    \"responsive_all\",\n",
        "    \"thalamus_responsive\",\"thalamus\",\n",
        "]\n",
        "\n",
        "MODEL_ROOT = Path(\"/content/drive/My Drive/rSLDS/rSLDS-Model-Outputs\")\n",
        "DEST_ROOT  = Path(\"/content/drive/My Drive/rSLDS/All-Plots/vector_fields\")\n",
        "\n",
        "def has_needed_files(model_dir: Path) -> bool:\n",
        "    return (\n",
        "        glob.glob(str(model_dir / \"x_hat*.npy\")) and\n",
        "        glob.glob(str(model_dir / \"z_hat*.npy\")) and\n",
        "        glob.glob(str(model_dir / \"*model*.pkl\"))\n",
        "    )\n",
        "\n",
        "plt.ioff()\n",
        "\n",
        "for rid in RAT_IDS:\n",
        "    rat_root = MODEL_ROOT / f\"Rat{rid}-Model-Outputs\"\n",
        "    if not rat_root.exists():\n",
        "        print(f\"[Rat {rid}]root folder missing\")\n",
        "        continue\n",
        "\n",
        "    for suffix in MODEL_SUFFIXES:\n",
        "        model_sub = f\"models_Rat{rid}_{suffix}\"\n",
        "        model_dir = rat_root / model_sub\n",
        "\n",
        "        if not has_needed_files(model_dir):\n",
        "            continue\n",
        "\n",
        "        try:\n",
        "            print(f\"[Rat {rid}] {suffix:22s} → vector field …\")\n",
        "            plot_rslds_vector_field(\n",
        "                model_dir = str(model_dir),\n",
        "                grid_size = 30,\n",
        "                cmap      = \"plasma\",\n",
        "                density   = 1.0,\n",
        "            )\n",
        "\n",
        "            fig = plt.gcf()\n",
        "            out_dir = DEST_ROOT / f\"Rat{rid}\" / model_sub\n",
        "            out_dir.mkdir(parents=True, exist_ok=True)\n",
        "            fig.savefig(out_dir / \"vector_field.png\", dpi=300, bbox_inches=\"tight\")\n",
        "            plt.close(fig)\n",
        "\n",
        "            print(f\"saved → {out_dir}/vector_field.png\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\" couldnt ({e.__class__.__name__}: {e})\")\n",
        "            traceback.print_exc(limit=1)\n",
        "            continue\n",
        "plt.ion()\n"
      ],
      "metadata": {
        "id": "WPxlY6OY-JPW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Forward Simulation Error (FSE)"
      ],
      "metadata": {
        "id": "crwkXLNR0Occ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "When simulating the rSLDS forward in time, the model predicts the next state based on its current state and the active linear system. The forward simulation error is then calculated by comparing this predicted state with the actual observed state at the next time step. A common metric for this is the mean squared error (MSE) or a normalized version of it. We used Forward Simulation Error (FSE) to test how well the rSLDS captured latent dynamics. So I  used Forward Simulation Error (FSE) to test how well the rSLDS captured latent dynamics. Starting from the inferred latent state xt, rolled the model forward for Δt steps and compared predictions to the posterior mean at 𝑥𝑡+Δ𝑡.\n",
        "If you see where the rat is right now, you can guess pretty well where it will be one step later (small FSE).\n",
        "\n",
        "If you try to guess 10 steps later without looking again, your guess will drift off — because the rat might turn, speed up, or freeze (big FSE).\n",
        "\n",
        "How fast the model's predictions drift away from reality."
      ],
      "metadata": {
        "id": "7HtamW9gelk5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "RAT_IDS        = [3,4,8,10,11,13,14,15,16,17,18,19,20,21]\n",
        "MODEL_SUFFIXES = [\n",
        "    \"ventral_responsive\",\"ventral\",\n",
        "    \"dorsal_responsive\",\"dorsal\",\n",
        "    \"responsive_all\",\n",
        "    \"thalamus_responsive\",\"thalamus\",\n",
        "]\n",
        "\n",
        "MODEL_ROOT = Path(\"/content/drive/My Drive/rSLDS/rSLDS-Model-Outputs\")\n",
        "DEST_ROOT  = Path(\"/content/drive/My Drive/rSLDS/All-Plots/fse\")\n",
        "\n",
        "def find_model_fname(model_dir: Path) -> str | None:\n",
        "    for name in (\"my_model.pkl\", \"rSLDS.pkl\"):\n",
        "        if (model_dir / name).exists():\n",
        "            return name\n",
        "    for pat in (\"*model*.pkl\", \"*.pkl\"):\n",
        "        hits = glob.glob(str(model_dir / pat))\n",
        "        if hits:\n",
        "            return Path(hits[0]).name\n",
        "    return None\n",
        "\n",
        "plt.ioff()\n",
        "\n",
        "for rid in RAT_IDS:\n",
        "    rat_root = MODEL_ROOT / f\"Rat{rid}-Model-Outputs\"\n",
        "    if not rat_root.exists():\n",
        "        print(f\"[Rat {rid}] root folder missing — skipped\")\n",
        "        continue\n",
        "\n",
        "    for suffix in MODEL_SUFFIXES:\n",
        "        model_sub = f\"models_Rat{rid}_{suffix}\"\n",
        "        model_dir = rat_root / model_sub\n",
        "\n",
        "        x_path, z_path = model_dir / \"x_hat.npy\", model_dir / \"z_hat.npy\"\n",
        "        if not (x_path.exists() and z_path.exists()):\n",
        "            continue\n",
        "\n",
        "        model_fname = find_model_fname(model_dir)\n",
        "        if model_fname is None:\n",
        "            continue\n",
        "\n",
        "        try:\n",
        "            print(f\"[Rat {rid}] {suffix:22s} → FSE …\")\n",
        "            fse_vals = compute_and_plot_fse(\n",
        "                model_dir   = model_dir,\n",
        "                n_steps     = 10,\n",
        "                plot        = False,\n",
        "                model_fname = model_fname,\n",
        "            )\n",
        "\n",
        "            fig, ax = plt.subplots(figsize=(5, 3))\n",
        "            x = np.arange(1, len(fse_vals) + 1)\n",
        "            ax.plot(x, fse_vals, marker='o')\n",
        "            ax.set_xlabel('Δt steps ahead')\n",
        "            ax.set_ylabel('Forward Simulation MSE (latents)')\n",
        "            ax.set_title('Forward Simulation Error (FSE)')\n",
        "            ax.spines[['top','right']].set_visible(False)\n",
        "            fig.tight_layout()\n",
        "\n",
        "            out_dir = DEST_ROOT / f\"Rat{rid}\" / model_sub\n",
        "            out_dir.mkdir(parents=True, exist_ok=True)\n",
        "            fig.savefig(out_dir / \"FSE.png\", dpi=300, bbox_inches=\"tight\")\n",
        "            np.save(out_dir / \"FSE.npy\", np.asarray(fse_vals, float))\n",
        "            plt.close(fig)\n",
        "\n",
        "            print(f\"saved → {out_dir}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"FSE failed ({e.__class__.__name__}: {e})\")\n",
        "            traceback.print_exc(limit=1)\n",
        "            continue\n",
        "\n",
        "plt.ion()\n"
      ],
      "metadata": {
        "id": "3QpQxzQZ1PwS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}